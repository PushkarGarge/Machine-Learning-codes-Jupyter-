# -*- coding: utf-8 -*-
"""Linear Regression on Boston Housing Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GJfC4_qGjxB8D_IRkf4X67T9FmWxnO-F

## importing all the libraries required for the Linear Regression

# Linear Regression :
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

"""Dataset"""

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("BostonHousing.csv")

df.head()

df.tail()

prices = df['medv']
features = df.drop('medv',axis = 1)

"""Calculation for Minumum, Maximum, Mean, Median, Standard deviation of prices :"""

# Calculation  of Minimum price
minimum_price = np.mean(prices)
# Calculation of Maximum price 
maximum_price = np.max(prices)
# Calculation of Mean price
mean_price = np.mean(prices)
# Calculation of Median price
median_price = np.median(prices)
# Calculatoin of Standard deviation 
std_price = np.std(prices)
# To show aboce calculated values 

print("Minimum price: ${:,.2f}".format(minimum_price))
print("Maximum price: ${:,.2f}".format(maximum_price))
print("Mean price: ${:,.2f}".format(mean_price))
print("Median price ${:,.2f}".format(median_price))
print("Standard deviation of prices: ${:,.2f}".format(std_price))

"""Pre-Processing on the data;
Missing Value / Data Type / correlation
"""

df.isnull().sum()

df.info()

cor = df.corr()

cor

"""Correlation Visualiazation using heatmap"""

plt.figure(figsize=(10,10))
sns.heatmap(df.corr(),annot=True,cmap="viridis")
plt.show()

"""Scatter Plot for rm and medv  :"""

plt.figure()
plt.scatter(df["rm"],df["medv"])
plt.show()

"""Scatter Plot for lstat and medv  :"""

plt.figure()
plt.scatter(df["lstat"],df["medv"])
plt.show()

"""Scatter Plot for ptratio and medv  :"""

plt.figure()
plt.scatter(df["ptratio"],df["medv"])
plt.show()

"""Seprating the target and features :"""

X = df[["rm"]]
y = df["medv"]

"""Seprate training and testing data :"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=1)

model = LinearRegression()

"""ols : oridinary least Square
 theta1 = sum(x-xbar)(y-ybar)/(x-xbar)2
 theta0 = y - theta1x
"""

model.fit(X_train,y_train)

model.intercept_

model.coef_

y_pred = model.predict(X_test)

"""Model Evaluation  :  Mean Squared Error & Root of mse & R2 Score"""

from sklearn.metrics import mean_squared_error, r2_score

mse  = mean_squared_error(y_test,y_pred)

mse

rmse = np.sqrt(mse)

rmse

r2 = r2_score(y_test,y_pred)

r2

"""Output values of mse  / rmse and r2 :"""

print("mse: {}, rmse: {}, r2: {}".format(mse,rmse,r2))

"""Plotting the model :"""

plt.figure()
plt.scatter(X_test,y_test)
plt.plot(X_test,y_pred)
plt.show()

"""Now , for ltest and medv column :"""

X = df[["lstat"]]
y = df["medv"]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=1)

model = LinearRegression()
model.fit(X_train,y_train)
print(model.intercept_)
print(model.coef_)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test,y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test,y_pred)
print("mse: {}, rmse: {}, r2: {}".format(mse,rmse,r2))

"""Plotting the Model :"""

plt.figure()
plt.scatter(X_test,y_test)
plt.plot(X_test,y_pred)
plt.show()

"""Now , for ptratio and medv column :"""

X = df[["ptratio"]]
y = df["medv"]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=1)

model = LinearRegression()
model.fit(X_train,y_train)
print(model.intercept_)
print(model.coef_)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test,y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test,y_pred)
print("mse: {}, rmse: {}, r2: {}".format(mse,rmse,r2))

plt.figure()
plt.scatter(X_test,y_test)
plt.plot(X_test,y_pred)
plt.show()

"""# Multiple Linear Regression :"""

X = df[["rm","lstat","ptratio"]]
y = df["medv"]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=1)

model = LinearRegression()
model.fit(X_train,y_train)
print(model.intercept_)
print(model.coef_)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test,y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test,y_pred)
print("mse: {}, rmse: {}, r2: {}".format(mse,rmse,r2))

# # multi-dimentional plotting trick : y_pred and residual (assumption : linearity)
residual = y_test - y_pred

residual

"""Scatter plot of y_pred & residual :"""

plt.figure()
plt.scatter(y_pred,residual)
plt.show()

"""Residual Histogram : (assumption : normal distribution)"""

plt.figure()
sns.distplot(residual)
plt.show()

"""# Polynomial Regression :"""

from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(2)

X = df[["rm","lstat"]]
y = df["medv"]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=1)

X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

model = LinearRegression()

model.fit(X_train_poly, y_train)
y_pred = model.predict(X_test_poly)

mse = mean_squared_error(y_test,y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test,y_pred)

print("mse: {}, rmse: {}, r2: {}".format(mse,rmse,r2))
residual = y_test - y_pred

plt.figure()
sns.distplot(residual)
plt.show()

